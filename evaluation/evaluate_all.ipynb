{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db37fb2a2f45477b",
   "metadata": {},
   "source": [
    "# Hardware\n",
    "As we manipulate rather big dataframes we need >80GB of free system memory.\n",
    "\n",
    "# Install\n",
    "Need:\n",
    "* LaTeX `apt-get install cm-super texlive texlive-latex-extra texlive-fonts-recommended dvipng texlive-science pandoc texlive-xetex`\n",
    "* Libeigen: `apt-get install libeigen3-dev`\n",
    "* Python pip: `apt-get install python3-pip` and update `pip install -U pip`\n",
    "* Local stuff: `pip install -r requirements.txt`\n",
    "* Misc pypi: `pip install pandas matplotlib seaborn scienceplots numpy tqdm`\n",
    "* Base opt itself: `pip install ..`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45250e03e9524e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y cm-super texlive texlive-latex-extra texlive-fonts-recommended dvipng texlive-science pandoc texlive-xetex libeigen3-dev python3-pip\n",
    "!pip install -U pip\n",
    "!pip install -r requirements.txt\n",
    "!pip install pandas matplotlib seaborn scienceplots numpy tqdm\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ad422fbab18779",
   "metadata": {},
   "source": [
    "Inside docker container run `jupyter lab --allow-root --ip=0.0.0.0` to start the notebook server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e3653efe9278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scienceplots  # noqa\n",
    "from tqdm import tqdm\n",
    "\n",
    "from base_opt.utilities import eval_utils\n",
    "from base_opt.utilities.file_locations import ROOT\n",
    "\n",
    "# Set up LaTeX rendering\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r\"\"\"\n",
    "    \\usepackage{siunitx}\n",
    "\"\"\")\n",
    "\n",
    "# Some constants\n",
    "timeout = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e0549fec9b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_opt.base_opt.BaseOptimizer import BOOptimizer\n",
    "\n",
    "n_initial_points = BOOptimizer.best_hps['n_initial_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4accf43ada67a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# csv dtype definition\n",
    "csv_dtype = {\n",
    "    'Step': int,\n",
    "    # 'Action': 'numpy.ndarray',\n",
    "    'Reward': float,\n",
    "    'Solution': 'string',\n",
    "    'Valid Solution': bool,\n",
    "    'Run Time': float,\n",
    "    'Fail Reason': 'string',\n",
    "    'Reward Fail': float,\n",
    "    'Optimizer Runtime': float,\n",
    "    'Task ID': 'category',\n",
    "    'Algorithm': 'category',\n",
    "    'Optimizer Spec': 'string',\n",
    "    'Seed': int,\n",
    "    'Success': bool,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22285bcefa8bf85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative file locator - load mixed GNU parallels output with Set/, Space/, Alg/, Seed/ directories\n",
    "files = {}\n",
    "zip_file = ZipFile(ROOT.joinpath('data', 'outdir_test_1200.zip'))\n",
    "for csv_file in tqdm(zip_file.namelist()):\n",
    "    if not csv_file.endswith('_raw.csv'):\n",
    "        print(f\"Skipping {csv_file}\")\n",
    "        continue\n",
    "    # Find Task Set, Action Space, Algorithm, Seed\n",
    "    if re.search(r'(?<=Set/)(.*?)/', str(csv_file)) is None:\n",
    "        if 'outdir_simple' in str(csv_file):\n",
    "            task_set = 'test_simple'\n",
    "        elif 'outdir_edge' in str(csv_file):\n",
    "            task_set = 'test_edge'\n",
    "    else:\n",
    "        task_set = re.search(r'(?<=Set/)(.*?)/', str(csv_file)).group(0)[:-1]\n",
    "    action = re.search(r'(?<=Space/)(.*?)/', str(csv_file)).group(0)[:-1]\n",
    "    algorithm = re.search(r'(?<=Alg/)(.*?)/', str(csv_file)).group(0)[:-1]\n",
    "    seed = re.search(r'(?<=Seed/)(\\d)+_raw.csv', str(csv_file)).group(0)[:-8]  # Remove _raw.csv\n",
    "    files[csv_file] = (task_set, action, algorithm, seed)\n",
    "\n",
    "result_df = []\n",
    "for file, (task_set, action, algorithm, seed) in (pbar := tqdm(files.items())):\n",
    "    pbar.set_description(f\"Processing {file}\")\n",
    "    df = pd.read_csv(zip_file.open(file), dtype=csv_dtype)\n",
    "    df['Task Set'] = task_set\n",
    "    df['Action Space'] = action\n",
    "    assert df['Algorithm'].nunique() == 1\n",
    "    assert df['Seed'].nunique() == 1\n",
    "    assert df['Algorithm'].unique()[0] == algorithm\n",
    "    assert df['Seed'].unique()[0] == int(seed)\n",
    "    result_df.append(df)\n",
    "    \n",
    "result_df = pd.concat(result_df, ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3e4f1b11e4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b460c55791cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split edge case task set\n",
    "result_df.loc[result_df['Task Set'] == 'test_edge', 'Task Set'] += \"_\" + result_df.loc[result_df['Task Set'] == 'test_edge', 'Task ID'].str.extract(r\"(?<=base_opt\\/edge_case\\/).*((?:medium)|(?:hard))\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7214ee927cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "print(f\"{result_df['Task Set'].unique() = }\")\n",
    "print(f\"{result_df['Action Space'].unique() = }\")\n",
    "print(f\"{result_df['Algorithm'].unique() = }\")\n",
    "print(f\"{result_df['Seed'].unique() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74159b4ada7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_clean = eval_utils.cleanup_preprocess_results(\n",
    "    result_df,\n",
    "    group_by=['Task Set', 'Action Space', 'Algorithm', 'Task ID', 'Seed'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f042c73eff6522",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29c59c37c51e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best solution ID per task id, algorithm and action space\n",
    "import pickle\n",
    "best_solutions = result_df_clean[result_df_clean['Valid Solution']].sort_values('Reward', ascending=False).drop_duplicates(['Task ID', 'Algorithm', 'Action Space'])\n",
    "uuid_list = {}\n",
    "for alg, action in best_solutions[['Algorithm', 'Action Space']].drop_duplicates().itertuples(index=False):\n",
    "    item = best_solutions[(best_solutions['Algorithm'] == alg) & (best_solutions['Action Space'] == action)]\n",
    "    for taskID, reward, sol_uuid in zip(item['Task ID'].tolist(), item['Reward'].tolist(), item['Solution'].tolist()):\n",
    "        uuid_list[alg, action, taskID, reward] = sol_uuid\n",
    "with open(ROOT.joinpath('evaluation', 'best_solutions.pkl'), 'wb') as f:\n",
    "    pickle.dump(uuid_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374003acb046dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_norm_time = eval_utils.normalize_time(result_df_clean, group_by=['Task Set', 'Action Space', 'Algorithm', 'Task ID', 'Seed'], sampling_time='30s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dc59bd3ec1bf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{result_df_norm_time['Task Set'].unique() = }\")\n",
    "print(f\"{result_df_norm_time['Algorithm'].unique() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2319735ee64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save normalized time df\n",
    "result_df_norm_time.to_csv(ROOT.joinpath('data', 'normalized_time.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6875a04057e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip ../data/normalized_time.zip ../data/normalized_time.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67157310885d34",
   "metadata": {},
   "source": [
    "# Basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f399e1baea617",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_utils.print_step_count(result_df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cbe267fcb0aea3",
   "metadata": {},
   "source": [
    "# Convergence per task set\n",
    "Can be restarted from here based on normalized_time.csv with less memory usage (few GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0ad9ec172fd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalized time df\n",
    "result_df_norm_time = pd.read_csv(ROOT.joinpath('data', 'normalized_time.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9707511de2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_norm_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88bb75fa63a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_norm_time['Algorithm'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974883b26ff4e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_norm_time['Task Set'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda1658aa8ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_df_norm_time['Run Time'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42207099d9ea7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_norm_time['Seed'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73fdbb7c23f0b8",
   "metadata": {},
   "source": [
    "## Split Success Rate and Mean Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a9598d961f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bootstrap\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "res = {}\n",
    "n_resamples = 9999  #  1000\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "for row_name, row_group in tqdm(result_df_norm_time.groupby('Action Space'), desc='Action Space'):\n",
    "    for col_name, col_group in tqdm(row_group.groupby('Task Set'), desc='Task Set'):\n",
    "        for hue_name, hue_group in tqdm(col_group.groupby('Algorithm'), desc='Algorithm'):\n",
    "            line_prefix = f\"{row_name}.{col_name}.{hue_name}.\"\n",
    "            # Success rate\n",
    "            success_df = hue_group.pivot_table(index='Run Time', columns=['Seed', 'Task ID'], values='Success Till Step')\n",
    "            success_values = success_df.to_numpy(dtype=np.float64)\n",
    "            success_values += 1e-9 * rng.random(success_values.shape)\n",
    "            bs_success = bootstrap(success_values[np.newaxis, :], np.nanmean, n_resamples=n_resamples, axis=-1, random_state=rng)\n",
    "            # Mean cost of successful steps\n",
    "            cost_df = hue_group.pivot_table(index='Run Time', columns=['Seed', 'Task ID'], values='Maximum Reward')\n",
    "            cost_df[cost_df == -50.] = np.nan  # Filter non-solved\n",
    "            cost_values = cost_df.to_numpy(dtype=np.float64)\n",
    "            cost_values += 1e-9 * rng.random(cost_values.shape)\n",
    "            bs_cost = bootstrap(cost_values[np.newaxis, :], np.nanmean, n_resamples=n_resamples, axis=-1, random_state=rng)\n",
    "            res[line_prefix + 'mean_cost'] = cost_df.mean(axis='columns')\n",
    "            res[line_prefix + 'low_cost'] = bs_cost.confidence_interval.low\n",
    "            res[line_prefix + 'high_cost'] = bs_cost.confidence_interval.high\n",
    "            res[line_prefix + 'mean_success_rate'] = success_df.mean(axis='columns')\n",
    "            res[line_prefix + 'low_success_rate'] = bs_success.confidence_interval.low\n",
    "            res[line_prefix + 'high_success_rate'] = bs_success.confidence_interval.high\n",
    "    #         break  # Stop earlier for debug\n",
    "    #     break  # Stop earlier for debug\n",
    "    # break  # Stop earlier for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17d729c717be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b03ded68bce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.to_datetime(pd.DataFrame(res).index).astype(int) / 1e9 / 60  # Unix time to min\n",
    "df = pd.DataFrame(res)\n",
    "df = abs(df)\n",
    "df.index = idx\n",
    "df.to_csv(ROOT.joinpath('data', 'cost_success.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1660b5fb60a89f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last row of df is table II -> success rate and cost at end of optimization\n",
    "df_tab_t_cpu = df.iloc[-1]\n",
    "# Split index - scope.set.alg.measurement\n",
    "df_tab_t_cpu.index = pd.MultiIndex.from_tuples(df_tab_t_cpu.index.str.split('.').tolist(), names=['Action Space', 'Task Set', 'Algorithm', 'Measurement'])\n",
    "df_tab_t_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b1e66996c24be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "list(itertools.product(['Random', 'GA', 'BO', 'SGD'], ['mean_cost', 'high_cost', 'low_cost']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39609027ff7acc04",
   "metadata": {},
   "source": [
    "# Create Success Rate Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890fed3bc662552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cost_t_cpu = df_tab_t_cpu.unstack(level=['Algorithm', 'Measurement']).filter(regex='.*cost') * (-1)  # Switch high/low to low/high\n",
    "\n",
    "df_cost_t_cpu = df_cost_t_cpu[\n",
    "    itertools.product(['Random', 'GA', 'BO', 'SGD'], ['mean_cost', 'high_cost', 'low_cost'])\n",
    "].reindex(\n",
    "    ['test_simple', 'test_hard', 'test_realworld', 'test_edge_hard'],\n",
    "level=1)\n",
    "table_string = df_cost_t_cpu.to_latex(float_format='%.2f')\n",
    "table_string = re.sub(r'([+-]?[0-9]*[.][0-9]+)', r'\\\\qty{\\g<1>}{}', table_string)\n",
    "table_string = re.sub(r'test_simple', 'Simple', table_string)\n",
    "table_string = re.sub(r'test_hard', 'Hard', table_string)\n",
    "table_string = re.sub(r'test_realworld', 'Real', table_string)\n",
    "table_string = re.sub(r'test_edge_medium', 'Edge Medium', table_string)\n",
    "table_string = re.sub(r'test_edge_hard', 'Edge', table_string)\n",
    "table_string = re.sub(r'xyz\\}', r'Position}', table_string)\n",
    "table_string = re.sub(r'xyz_rotvec', r'\\\\parbox{1.2cm}{Position + Rotation}', table_string)\n",
    "table_string = re.sub(r'\\[t\\]', r'', table_string)\n",
    "table_string = re.sub(r'{r}', r'{c}', table_string)\n",
    "table_string = re.sub(r'llrrrrrrrrrrrr', r'll' + 4 * r'C@{ [}R@{, }L@{]\\\\hspace{4mm}}', table_string)\n",
    "table_string = re.sub(r'\\\\cline{1-14}', r'\\\\midrule', table_string)\n",
    "table_string = re.sub(r' &  & low & high & low & high & low & high & low & high \\\\\\\\', '', table_string)\n",
    "table_string = re.sub(r' & Algorithm', 'Action Space & Task Set', table_string)\n",
    "table_string = re.sub(r'Action Space & Task Set &  &  &  &  &  &  &  &  \\\\\\\\', '', table_string)\n",
    "print(table_string)\n",
    "df_cost_t_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64978f26c23f5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success_rate_t_cpu = df_tab_t_cpu.unstack(level=['Algorithm', 'Measurement']).filter(regex='.*success_rate') * 100\n",
    "df_success_rate_t_cpu = df_success_rate_t_cpu.reindex(['test_simple', 'test_hard', 'test_realworld', 'test_edge_hard'], level=1)\n",
    "df_success_rate_t_cpu = df_success_rate_t_cpu[['Random', 'GA', 'BO', 'SGD']]\n",
    "table_string = df_success_rate_t_cpu.to_latex(float_format='%.2f')\n",
    "table_string = re.sub(r'([+-]?[0-9]*[.][0-9]+)', r'\\\\qty{\\g<1>}{}', table_string)\n",
    "table_string = re.sub(r'test_simple', 'Simple', table_string)\n",
    "table_string = re.sub(r'test_hard', 'Hard', table_string)\n",
    "table_string = re.sub(r'test_realworld', 'Real', table_string)\n",
    "table_string = re.sub(r'test_edge_medium', 'Edge Medium', table_string)\n",
    "table_string = re.sub(r'test_edge_hard', 'Edge', table_string)\n",
    "table_string = re.sub(r'xyz\\}', r'Position}', table_string)\n",
    "table_string = re.sub(r'xyz_rotvec', r'\\\\parbox{1.2cm}{Position + Rotation}', table_string)\n",
    "table_string = re.sub(r'\\[t\\]', r'', table_string)\n",
    "table_string = re.sub(r'{r}', r'{c}', table_string)\n",
    "table_string = re.sub(r'llrrrrrrrrrrrr', r'll' + 4 * r'C@{ [}R@{, }L@{]\\\\hspace{4mm}}', table_string)\n",
    "table_string = re.sub(r'\\\\cline{1-14}', r'\\\\midrule', table_string)\n",
    "table_string = re.sub(r' &  & low & high & low & high & low & high & low & high \\\\\\\\', '', table_string)\n",
    "table_string = re.sub(r' & Algorithm', 'Action Space & Task Set', table_string)\n",
    "table_string = re.sub(r'Action Space & Task Set &  &  &  &  &  &  &  &  \\\\\\\\', '', table_string)\n",
    "print(table_string)\n",
    "df_success_rate_t_cpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
