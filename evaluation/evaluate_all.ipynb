{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scienceplots  # noqa\n",
    "from tqdm import tqdm\n",
    "\n",
    "from base_opt.utilities import eval_utils\n",
    "from base_opt.utilities.file_locations import ROOT\n",
    "\n",
    "# Set up LaTeX rendering\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('text.latex', preamble=r\"\"\"\n",
    "    \\usepackage{siunitx}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff23a7a4bcf7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# csv dtype definition\n",
    "csv_dtype = {\n",
    "    'Step': int,\n",
    "    # 'Action': 'numpy.ndarray',\n",
    "    'Reward': float,\n",
    "    'Solution': 'string',\n",
    "    'Valid Solution': bool,\n",
    "    'Run Time': float,\n",
    "    'Fail Reason': 'string',\n",
    "    'Reward Fail': float,\n",
    "    'Optimizer Runtime': float,\n",
    "    'Task ID': 'category',\n",
    "    'Algorithm': 'category',\n",
    "    'Optimizer Spec': 'string',\n",
    "    'Seed': int,\n",
    "    'Success': bool,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef426a6983f7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract raw data\n",
    "ZipFile(ROOT.joinpath('data', 'outdir_test_1200.zip')).extractall(ROOT.joinpath('data', 'outdir_test_1200'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bdb02f1b2f0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative file locator - load mixed GNU parallels output with Set/, Space/, Alg/, Seed/ directories\n",
    "files = {}\n",
    "for csv_file in tqdm(ROOT.joinpath('data', 'outdir_test_1200').rglob('**/*_raw.csv')):\n",
    "    # Find Task Set, Action Space, Algorithm, Seed\n",
    "    if re.search(r'(?<=Set/)(.*?)/', str(csv_file)) is None:\n",
    "        if 'outdir_simple' in str(csv_file):\n",
    "            task_set = 'test_simple'\n",
    "        elif 'outdir_edge' in str(csv_file):\n",
    "            task_set = 'test_edge'\n",
    "    else:\n",
    "        task_set = re.search(r'(?<=Set/)(.*?)/', str(csv_file)).group(0)[:-1]\n",
    "    action = re.search(r'(?<=Space/)(.*?)/', str(csv_file)).group(0)[:-1]\n",
    "    algorithm = re.search(r'(?<=Alg/)(.*?)/', str(csv_file)).group(0)[:-1]\n",
    "    seed = re.search(r'(?<=Seed/)(\\d)+_raw.csv', str(csv_file)).group(0)[:-8]  # Remove _raw.csv\n",
    "    files[csv_file] = (task_set, action, algorithm, seed)\n",
    "\n",
    "result_df = []\n",
    "for file, (task_set, action, algorithm, seed) in tqdm(files.items()):\n",
    "    df = pd.read_csv(file, dtype=csv_dtype)\n",
    "    df['Task Set'] = task_set\n",
    "    df['Action Space'] = action\n",
    "    assert df['Algorithm'].nunique() == 1\n",
    "    assert df['Seed'].nunique() == 1\n",
    "    assert df['Algorithm'].unique()[0] == algorithm\n",
    "    assert df['Seed'].unique()[0] == int(seed)\n",
    "    result_df.append(df)\n",
    "    \n",
    "result_df = pd.concat(result_df, ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5aa7bc7d69beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_opt.base_opt.BaseOptimizer import BOOptimizer\n",
    "\n",
    "timeout = 1200\n",
    "n_initial_points = BOOptimizer.best_hps['n_initial_points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dedb609ea54ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c727196-d63b-4e36-a0d1-16a97d64fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split edge case task set\n",
    "result_df.loc[result_df['Task Set'] == 'test_edge', 'Task Set'] += \"_\" + result_df.loc[result_df['Task Set'] == 'test_edge', 'Task ID'].str.extract(r\"(?<=base_opt\\/edge_case\\/).*((?:medium)|(?:hard))\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21b2f80a063e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "print(f\"{result_df['Task Set'].unique() = }\")\n",
    "print(f\"{result_df['Action Space'].unique() = }\")\n",
    "print(f\"{result_df['Algorithm'].unique() = }\")\n",
    "print(f\"{result_df['Seed'].unique() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf9aa54f2e2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_clean = eval_utils.cleanup_preprocess_results(\n",
    "    result_df,\n",
    "    group_by=['Task Set', 'Action Space', 'Algorithm', 'Task ID', 'Seed'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6145d728f91307ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ca30f17d45818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best solution ID per task id, algorithm and action space\n",
    "import pickle\n",
    "best_solutions = result_df_clean[result_df_clean['Valid Solution']].sort_values('Reward', ascending=False).drop_duplicates(['Task ID', 'Algorithm', 'Action Space'])\n",
    "uuid_list = {}\n",
    "for alg, action in best_solutions[['Algorithm', 'Action Space']].drop_duplicates().itertuples(index=False):\n",
    "    uuid_list[alg, action] = best_solutions[(best_solutions['Algorithm'] == alg) & (best_solutions['Action Space'] == action)]['Solution'].tolist()\n",
    "with open(ROOT.joinpath('evaluation', 'best_solutions.pkl'), 'wb') as f:\n",
    "    pickle.dump(uuid_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1128dddbb824061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_norm_time = eval_utils.normalize_time(result_df_clean, group_by=['Task Set', 'Action Space', 'Algorithm', 'Task ID', 'Seed'], sampling_time='30s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b79ff590e09f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_norm_time['Task Set'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433667df7c226af",
   "metadata": {},
   "source": [
    "# Basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d784013fe84dd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_utils.print_step_count(result_df_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694cfa01410f82ff",
   "metadata": {},
   "source": [
    "# Convergence per task set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e9762cfa3c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_df = result_df_norm_time.copy()  # Plot cost not reward\n",
    "local_df['Maximum Reward'] = -1. * local_df['Maximum Reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4105e5a17c422dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_df['Action Space'] = local_df['Action Space'].replace({'xyz': 'Position', \n",
    "                                                             'xyz_rotvec': 'Position + Orientation'})\n",
    "local_df['Task Set'] = local_df['Task Set'].replace({\n",
    "    'test_simple': 'Simple', \n",
    "    'test_hard': 'Hard', \n",
    "    'test_realworld': 'Real',\n",
    "    'test_edge_medium': 'Edge Medium',\n",
    "    'test_edge_hard': 'Edge Hard'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed6191ed4dd815",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(['default', 'science', 'ieee', 'std-colors']):\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    f = sns.relplot(\n",
    "        data=local_df, \n",
    "        x='Run Time', \n",
    "        y='Maximum Reward', \n",
    "        col='Task Set', \n",
    "        row='Action Space',\n",
    "        # style='Action Space', \n",
    "        hue='Algorithm', \n",
    "        kind='line', \n",
    "        estimator='mean', \n",
    "        # err_style='bars',\n",
    "        facet_kws={'sharey': False}, \n",
    "        hue_order=['Dummy', 'Random', 'BO', 'GA', 'AdamOptimizer'],\n",
    "        col_order=['Simple', 'Hard', 'Real', 'Edge Medium', 'Edge Hard'],\n",
    "        aspect=4 / 3, \n",
    "        height=7.16 / 4,  # two column is 7.16 inches wide\n",
    "        seed=42)  # Fix for reproducible confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d43f8fd86752c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, ax in enumerate(f.axes.flat):\n",
    "    ax.set_xlabel(r\"Run Time $[\\si{\\second}]$\")\n",
    "    if idx % 5 == 0:\n",
    "        ax.set_ylabel(r\"Minimum Cost $[\\si{\\second}]$\")\n",
    "    else:\n",
    "        ax.set_ylabel(None)\n",
    "    ax.set_xlim(pd.Timestamp(0, unit=\"s\"), pd.Timestamp(timeout, unit=\"s\"))\n",
    "    ax.set_xticks(\n",
    "        [pd.Timestamp(t, unit=\"s\") for t in np.linspace(0, timeout, 5)], labels=[f\"{t:.0f}\" for t in np.linspace(0, timeout, 5)])\n",
    "    ax.set_title(ax.get_title().replace('Task Set = ', ''))\n",
    "    ax.set_title(ax.get_title().replace('Action Space = ', ''), fontsize=10)\n",
    "sns.move_legend(f, \"upper center\", bbox_to_anchor=(0.48, 0), ncol=4)\n",
    "f._legend.set_title(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b739f5214f82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize y-axis per column\n",
    "for col in range(f.axes.shape[1]):\n",
    "    y_lim_lower = min(a.get_ylim()[0] for a in f.axes[:, col])\n",
    "    y_lim_upper = max(a.get_ylim()[1] for a in f.axes[:, col])\n",
    "    for row in range(f.axes.shape[0]):\n",
    "        f.axes[row, col].set_ylim(y_lim_lower, y_lim_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99966cc391586697",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e183e85542dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig(ROOT.joinpath('evaluation', 'ConvergencePlot.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc58e5464bb61d9",
   "metadata": {},
   "source": [
    "# Create Success Rate Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5536459f39ff7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "success_per_trial = result_df_clean.groupby(['Task Set', 'Action Space', 'Algorithm', 'Task ID', 'Seed'])['Success'].any()\n",
    "success_per_trial *= 100  # Convert to percentage\n",
    "tab_success_rate = success_per_trial.groupby(['Action Space', 'Task Set', 'Algorithm']).mean().unstack(-1).reindex(['test_simple', 'test_hard', 'test_realworld', 'test_edge_medium', 'test_edge_hard'], level=1)[['Dummy', 'Random', 'BO', 'GA', 'AdamOptimizer']]\n",
    "tab_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c789db4003c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table succ_rate_diff\n",
    "table_string = tab_success_rate.to_latex(float_format='%.2f')\n",
    "table_string = re.sub(r'([+-]?[0-9]*[.][0-9]+)', r'$\\\\qty{\\g<1>}{\\\\percent}$', table_string)\n",
    "table_string = re.sub(r'test_simple', 'Simple', table_string)\n",
    "table_string = re.sub(r'test_hard', 'Hard', table_string)\n",
    "table_string = re.sub(r'test_realworld', 'Real', table_string)\n",
    "table_string = re.sub(r'test_edge_medium', 'Edge Medium', table_string)\n",
    "table_string = re.sub(r'test_edge_hard', 'Edge Hard', table_string)\n",
    "table_string = re.sub(r'xyz\\}', r'Position}', table_string)\n",
    "table_string = re.sub(r'xyz_rotvec', r'\\\\parbox\\{1.2cm\\}\\{Position + Rotation}', table_string)\n",
    "table_string = re.sub(r'\\[t\\]', r'', table_string)\n",
    "print(table_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3f575fe969c01",
   "metadata": {},
   "source": [
    "## Best cost in different action spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d180914b16a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_per_trial = result_df_clean[result_df_clean['Task Set'] == 'test_simple'].groupby(['Action Space', 'Algorithm', 'Task ID', 'Seed'])['Maximum Reward'].max()  # Check for different task sets\n",
    "result_per_trial = result_per_trial.reset_index()\n",
    "result_per_trial['Hue'] = result_per_trial['Action Space'] + ' ' + result_per_trial['Algorithm']\n",
    "# sns.kdeplot(result_per_trial, x='Maximum Reward', clip=(-20., 0.), hue='Hue')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb01a0c13d97cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_per_trial.groupby(['Action Space', 'Algorithm'])['Maximum Reward'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d83479ac33b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_per_trial['Minimum Cost'] = -result_per_trial['Maximum Reward']\n",
    "result_per_trial['Action Space'].replace({'xyz': 'Position', \n",
    "                                          'xyz_rotvec': 'Position + Rotation'},\n",
    "                                           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879c971f92e27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(['default', 'science', 'ieee', 'std-colors']):\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    fig = plt.figure(figsize=(3.4, 2.55))  # IEEE column width and 4:3\n",
    "    sns.boxplot(\n",
    "        data=result_per_trial, \n",
    "        x='Algorithm', \n",
    "        y='Minimum Cost', \n",
    "        hue='Action Space', \n",
    "        order=['Dummy', 'Random', 'BO', 'GA', 'AdamOptimizer'],\n",
    "        palette=sns.color_palette()[4:6],\n",
    "        flierprops=dict(marker='*', markersize=2, linestyle='none', alpha=0.5),\n",
    "        ax=plt.gca())\n",
    "    \n",
    "    fig.gca().set_ylabel(r\"Minimum Cost $[\\si{\\second}]$\")\n",
    "    fig.gca().set_xlabel(None)\n",
    "    fig.gca().legend(loc='upper center', title=None)\n",
    "    sns.move_legend(fig.gca(), \"upper center\", bbox_to_anchor=(0.5, 1.12), ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eda15fed9bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80159bee32440368",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(ROOT.joinpath('evaluation', 'AlgDomainCostPlot.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18601d416948407d",
   "metadata": {},
   "source": [
    "# Check if some tasks need rotvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1c4a6ad43dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with final reward for each task, action space, algorithm, and seed\n",
    "local_df = result_df_clean[result_df_clean['Algorithm'] != 'Dummy'].copy()\n",
    "final_reward = local_df.groupby(['Action Space', 'Algorithm', 'Task ID', 'Seed'])['Maximum Reward'].last()\n",
    "final_reward = final_reward.reset_index()\n",
    "final_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df902dc1bd8f8c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotvec_final_reward = final_reward[final_reward['Action Space'] == 'xyz_rotvec']\n",
    "rotvec_final_reward = rotvec_final_reward.set_index(['Task ID', 'Algorithm', 'Seed'])\n",
    "rotvec_final_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627b2a2e9f591a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz_final_reward = final_reward[final_reward['Action Space'] == 'xyz']\n",
    "xyz_final_reward = xyz_final_reward.set_index(['Task ID', 'Algorithm', 'Seed'])\n",
    "xyz_final_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce365f9221ea9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order by difference in mean to find tasks that profit from rotvec\n",
    "delta_mean = (final_reward[final_reward['Action Space'] == 'xyz'].groupby(['Task ID', ])['Maximum Reward'].mean() - \n",
    "              final_reward[final_reward['Action Space'] == 'xyz_rotvec'].groupby(['Task ID', ])['Maximum Reward'].mean())\n",
    "order_mean = delta_mean.sort_values(ascending=False).index\n",
    "delta_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0cda4a1dbdb728",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = (xyz_final_reward['Maximum Reward'] - rotvec_final_reward['Maximum Reward']).reset_index()  # TODO : This is point-wise compare; rather want to compare random draws over seeds and their expected difference\n",
    "sns.barplot(data=delta, x='Task ID', y='Maximum Reward', order=order_mean[:10].append(order_mean[-10:]))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccf8aa82a1825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try via permutation test\n",
    "from scipy.stats import permutation_test\n",
    "\n",
    "def statistic(x, y, axis):\n",
    "    return np.mean(x, axis=axis) - np.mean(y, axis=axis)\n",
    "\n",
    "def test_statistic(x, y, alternative):\n",
    "    res = permutation_test((x, y), statistic, vectorized=True, n_resamples=100_000, alternative=alternative, random_state=42)\n",
    "    print(f\"{res.pvalue = }\")\n",
    "    print(f\"{res.statistic = }\")\n",
    "    plt.figure()\n",
    "    plt.hist(res.null_distribution)\n",
    "    plt.show()\n",
    "\n",
    "# Test high mean difference\n",
    "best_task_id = order_mean[0]\n",
    "print(f\"{best_task_id = }\")\n",
    "test_statistic(\n",
    "    xyz_final_reward.loc[best_task_id].reset_index()['Maximum Reward'],\n",
    "    rotvec_final_reward.loc[best_task_id].reset_index()['Maximum Reward'],\n",
    "    'greater')\n",
    "# Test center mean difference\n",
    "median_task_id = order_mean[len(order_mean) // 2]\n",
    "print(f\"{median_task_id = }\")\n",
    "test_statistic(\n",
    "    xyz_final_reward.loc[median_task_id].reset_index()['Maximum Reward'],\n",
    "    rotvec_final_reward.loc[median_task_id].reset_index()['Maximum Reward'],\n",
    "    'two-sided')\n",
    "# Test low mean difference\n",
    "worst_task_id = order_mean[-1]\n",
    "print(f\"{worst_task_id = }\")\n",
    "test_statistic(\n",
    "    xyz_final_reward.loc[worst_task_id].reset_index()['Maximum Reward'],\n",
    "    rotvec_final_reward.loc[worst_task_id].reset_index()['Maximum Reward'],\n",
    "    'less')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ff0980a7653da",
   "metadata": {},
   "source": [
    "# Filter runtime statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b68fa339e119cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result_df_clean.copy()\n",
    "df['Step Time'] = (df['Step Time'].copy() - pd.Timestamp(0, unit=\"s\")).dt.total_seconds()\n",
    "df['Fail Reason'] = df['Fail Reason'].replace(\n",
    "    {'Path planning timeout': 'Path planning failed',\n",
    "     'Invalid Path': 'Path planning failed'}\n",
    ")\n",
    "# Proper multi-line lables\n",
    "label_order = {\n",
    "    'Robot Length Filter': 'Robot\\nLength',\n",
    "    'Simple IK Filter': 'Simple\\nIK',\n",
    "    'IK Filter': 'IK\\nFilter',\n",
    "    'Path planning failed': 'Path\\nplanning',\n",
    "    'No failure': 'No\\nfailure',\n",
    "}\n",
    "df['Fail Reason'] = df['Fail Reason'].replace(label_order)\n",
    "fail_reasons = [f for f in eval_utils.FAIL_REASON_ORDER if f in df['Fail Reason'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc3bb3a57fa06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df[df['Fail Reason'].isna()]['Valid Solution'].unique()) == 1, \"There are NAs in Fail Reason without a valid solution\"\n",
    "df['Fail Reason'].fillna('No\\nfailure', inplace=True)\n",
    "df['Fail Reason'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123093b19dc842f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(['default', 'science', 'ieee', 'std-colors']):\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    fig = plt.figure(figsize=(3.4, 2.55))  # IEEE column width and 4:3\n",
    "    sns.boxplot(data=df, \n",
    "                x='Fail Reason',\n",
    "                y='Step Time', \n",
    "                hue='Algorithm',  \n",
    "                order=tuple(label_order.values()), \n",
    "                hue_order=['Dummy', 'Random', 'BO', 'GA', 'AdamOptimizer'],\n",
    "                # whis=(.135, 99.865),  # 3 sigma\n",
    "                flierprops=dict(marker='*', markersize=1, linestyle='none', alpha=0.3),\n",
    "                ax=fig.gca(),\n",
    "                )\n",
    "    fig.gca().set_yscale('log')\n",
    "    fig.gca().set_ylabel('Step Time $[\\si{\\second}]$')\n",
    "    fig.gca().set_xlabel(None)\n",
    "    fig.gca().legend(loc='lower right', title=None)\n",
    "    # fig.gca().set_title('Step Time per Algorithm and Failure Reason')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c2a446f3e23a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ec6893b49cb3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(ROOT.joinpath('evaluation', 'runtime_per_filter.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131cac2c03b5adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_clean.groupby(['Algorithm', 'Task Set'])['Step Time'].describe().reindex(['Dummy', 'Random', 'BO', 'GA', 'AdamOptimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18613b-3164-4c39-a07d-b1e0471cac53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
